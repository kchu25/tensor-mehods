{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from tensorly.decomposition import symmetric_power_iteration\n",
    "\n",
    "len_doc = 3 # number of words in each document; this is fake for now\n",
    "\n",
    "def matprint(mat, fmt=\"g\"):\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")\n",
    "  \n",
    "def svd_whiten(X, k):\n",
    "    # X: matrix to decompose\n",
    "    # k: rank approximation\n",
    "    \n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    # rank k approximation\n",
    "    U = U[:,:k]\n",
    "    s = s[:k]\n",
    "    Vt = Vt[:k,:]\n",
    "    \n",
    "    D_half = np.diag(np.sqrt(s))\n",
    "    W = np.diag(1./np.sqrt(s)) @ U.T\n",
    "\n",
    "    # so np.dot(np.dot(W.T, X),W) is the identity matrix\n",
    "        \n",
    "    return W , D_half, U\n",
    "\n",
    "\n",
    "def rank_k_pseudoinverse(X, k):\n",
    "    # pseudoinverse of rank k approximation of X\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "    return np.linalg.pinv(U[:,:k] @ np.diag(s[:k]) @ Vt[:k,:])\n",
    "        \n",
    "def model_1():\n",
    "    component_param = {0: np.array([0.31, 0.25, 0.44]   ),\n",
    "                      1: np.array([0.1, 0.1, 0.8]),\n",
    "                      2: np.array([0.9, 0.03, 0.07])}\n",
    "    h_weights = np.array([0.1, 0.6, 0.3])\n",
    "    return component_param, h_weights\n",
    "\n",
    "def model_2():\n",
    "    component_param = {0: np.array([.1, .1, .1, .3, .4]),\n",
    "                      1: np.array([.15, 0.05, 0.8, 0 ,0]),\n",
    "                      2: np.array([.2, 0.15, 0.3, .1, .25])}\n",
    "    h_weights = np.array([0.1, 0.6, 0.3])\n",
    "    return component_param, h_weights\n",
    "\n",
    "\n",
    "def generate_data_fixed(data_size=10000):\n",
    "    # num_components = num_rows = num_views = 3\n",
    "    \n",
    "    component_param, h_weights = model_2() # subject to change\n",
    "    \n",
    "    comp_label = np.arange(0,len(h_weights))  # there are num_components of components; zero-indexing\n",
    "    observation_label = np.arange(0, len(component_param[0])) # assume for now all the range of observation are the same\n",
    "    \n",
    "    data = []\n",
    "    for i in range(data_size):\n",
    "        # choose a component\n",
    "        choose = np.random.choice(comp_label, p = h_weights)\n",
    "        datum = []\n",
    "        \n",
    "        # there are three words\n",
    "        # each doc has length 30\n",
    "        for _ in range(len_doc):\n",
    "            datum.append(np.random.choice(observation_label, p = component_param[choose]))            \n",
    "        data.append(tuple(datum))\n",
    "    \n",
    "    rank = len(h_weights)\n",
    "    obs_size = len(component_param[0])\n",
    "    \n",
    "    return rank, obs_size, component_param, h_weights, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank is the number of mixture components\n",
    "#   this is named rank because the observation matrix must have full column rank    \n",
    "# obs_size is the cardinality of the observation random variable\n",
    "#   right now it is assumed that every component has the same range\n",
    "#   this is reasonable as the vocabulary size is the same accross different documents\n",
    "    \n",
    "rank, obs_size, cp, h, data = generate_data_fixed(data_size=5000)\n",
    "len_data = len(data)\n",
    "identity = np.eye(obs_size)\n",
    "\n",
    "# dummy encoding\n",
    "get_identity_col = lambda col_num: identity[:, col_num] \n",
    "\n",
    "# create word count vector for each document\n",
    "c_ns = [np.sum(np.array(([get_identity_col(i) for i in datum])), axis=0) for datum in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the second- and third-order moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2f = np.zeros((obs_size,obs_size))\n",
    "\n",
    "for i in range(obs_size):\n",
    "    M_2f[i,i] = sum([(pow(c_ns[n][i],2)-c_ns[n][i])/(len_doc*(len_doc-1)) for n in range(len_data)])/len_data\n",
    "    \n",
    "for i in range(obs_size):\n",
    "    for j in range(i+1,obs_size):        \n",
    "        temp = sum([ ( c_ns[n][i]*c_ns[n][j] )/(len_doc*(len_doc-1)) for n in range(len_data)])/len_data\n",
    "        M_2f[i,j] = M_2f[j,i] = temp\n",
    "\n",
    "M_3f = np.zeros((obs_size,obs_size,obs_size))\n",
    "\n",
    "for i in range(obs_size):\n",
    "    M_3f[i,i,i] = sum([(pow(c_ns[n][i],3)-3*pow(c_ns[n][i],2)+2*c_ns[n][i])/(len_doc*(len_doc-1)*(len_doc-2)) for n in range(len_data)])/len_data\n",
    "    \n",
    "for i in range(obs_size):\n",
    "    for j in range(i+1,obs_size):        \n",
    "        temp = sum([(pow(c_ns[n][i],2)*c_ns[n][j]-c_ns[n][i]*c_ns[n][j])/(len_doc*(len_doc-1)*(len_doc-2)) for n in range(len_data)])/len_data\n",
    "        M_3f[i,i,j] = M_3f[i,j,i] = M_3f[j,i,i] = temp\n",
    "        \n",
    "        temp2 = sum([(pow(c_ns[n][j],2)*c_ns[n][i]-c_ns[n][j]*c_ns[n][i])/(len_doc*(len_doc-1)*(len_doc-2)) for n in range(len_data)])/len_data\n",
    "        M_3f[j,j,i] = M_3f[j,i,j] = M_3f[i,j,j] = temp2\n",
    "                \n",
    "for i in range(obs_size):\n",
    "    for j in range(i+1,obs_size):\n",
    "        for k in range(j+1,obs_size):        \n",
    "            temp = sum([( c_ns[n][i]*c_ns[n][j]*c_ns[n][k] )/(len_doc*(len_doc-1)*(len_doc-2)) for n in range(len_data)])/len_data\n",
    "            M_3f[i,j,k] = M_3f[i,k,j] = M_3f[j,i,k] = M_3f[j,k,i] = M_3f[k,i,j] = M_3f[k,j,i] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whiten the moment tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1  1.12167e-16  4.75909e-16  \n",
      "1.67349e-16            1  2.93986e-16  \n",
      "2.78209e-16  2.33218e-16            1  \n"
     ]
    }
   ],
   "source": [
    "W, D_half, U = svd_whiten(M_2f, rank) # a bit a cheating here by using rank variable\n",
    "whitened_t01 = tl.tenalg.multi_mode_dot(M_2f, [W, W], modes=[0,1])\n",
    "whitened_t012 = tl.tenalg.multi_mode_dot(M_3f, [W, W, W], modes=[0,1,2])\n",
    "matprint( W @ M_2f @ W.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [0.019 0.425 0.584]\n",
      "Params: \n",
      "[ 0.142 -0.143  0.057  0.49   0.43 ]\n",
      "[0.162 0.144 0.262 0.149 0.275]\n",
      "[ 0.157  0.046  0.798 -0.003 -0.003]\n"
     ]
    }
   ],
   "source": [
    "w = []\n",
    "u = []\n",
    "deflated = None\n",
    "for i in range(rank):\n",
    "    if deflated is None:        \n",
    "        w_temp, u_temp, deflated = symmetric_power_iteration(whitened_t012)        \n",
    "    else:\n",
    "        w_temp, u_temp, deflated = symmetric_power_iteration(deflated)\n",
    "    w.append(w_temp)\n",
    "    u.append(u_temp)\n",
    "\n",
    "recovered_h = np.array([pow(1/i,2) for i in w])\n",
    "print(\"weights: \", recovered_h)\n",
    "os = [w[index] * U @ D_half @ u_i for index, u_i in enumerate(u)]\n",
    "print(\"Params: \")\n",
    "for i in os:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asymmetric tensor power iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [0.019 0.425 0.584]\n",
      "Params: \n",
      "[ 0.153 -0.126  0.054  0.515  0.403]\n",
      "[0.166 0.144 0.263 0.15  0.276]\n",
      "[ 0.156  0.047  0.802 -0.003 -0.003]\n"
     ]
    }
   ],
   "source": [
    "M_2_pinv = rank_k_pseudoinverse(M_2f, 3)\n",
    "T = M_3f\n",
    "\n",
    "w = []\n",
    "u = []\n",
    "os = []\n",
    "deflated = None\n",
    "for i in range(rank):\n",
    "    u = np.random.rand(obs_size)\n",
    "    u = np.divide(u, np.linalg.norm(u)) # randomly draw a vector from the unit sphere\n",
    "    for _ in range(15):\n",
    "        u = tl.tenalg.multi_mode_dot(T, [M_2_pinv @ u, M_2_pinv @ u], modes=[1,2])\n",
    "        u = np.divide(u, np.linalg.norm(u))\n",
    "\n",
    "    \n",
    "    a=np.divide(u, np.sqrt(np.abs(np.dot(u, M_2_pinv @ u))))\n",
    "    lambda1 = tl.tenalg.multi_mode_dot(T, [M_2_pinv @ a ,M_2_pinv@ a, M_2_pinv @ a], modes=[0,1,2])\n",
    "    T = T -  abs(lambda1)*np.tensordot(np.tensordot(a,a,axes=0),a,axes=0)\n",
    "    os.append(a/np.sum(a))\n",
    "    w.append(pow(1/lambda1,2))\n",
    "\n",
    "\n",
    "print(\"weights: \",np.array(w))\n",
    "print(\"Params: \")\n",
    "for i in os:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
